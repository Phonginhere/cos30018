{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T02:33:42.478206Z",
     "start_time": "2024-09-30T02:33:42.476167Z"
    }
   },
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from yahoo_fin import stock_info as si\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import pandas as pd\n",
    "import os"
   ],
   "outputs": [],
   "execution_count": 63
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function to load and process a dataset with multiple features with the following\n",
    "requirements:\\\n",
    "a. This function will allow you to specify the start date and the end date for the whole\n",
    "dataset as inputs.\\\n",
    "    b. This function will allow you to deal with the NaN issue in the data.\\\n",
    "    c. This function will also allow you to use different methods to split the data into\n",
    "train/test data; e.g. you can split it according to some specified ratio of train/test and\n",
    "you can specify to split it by date or randomly.\\\n",
    "    d. This function will have the option to allow you to store the downloaded data on your\n",
    "local machine for future uses and to load the data locally to save time.\\\n",
    "    e. This function will also allow you to have an option to scale your feature columns and\n",
    "store the scalers in a data structure to allow future access to these scalers."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T03:07:48.089046Z",
     "start_time": "2024-09-30T03:07:48.078604Z"
    }
   },
   "source": [
    "def load_data(ticker, TEST_START='2020-01-01', TEST_END='2023-01-01', shuffle=True, dropNaN=True, split_by_ratio=True, split_by_date=False, split_date=None, test_size=0.2, feature_columns=[\"adjclose\", \"volume\", \"open\", \"high\", \"low\"], scale=True):\n",
    "    \"\"\"\n",
    "    Loads data from yahoo finance, then scaling, shuffle, and normalization.\n",
    "    :param ticker: (str/pd.DataFrame), the ticker you want to load, like META, AAPL,...\n",
    "    :param TEST_START: str, the start date of the test data (format: \"YYYY-MM-DD\")\n",
    "    :param TEST_END: str, the end date of the test data (format: \"YYYY-MM-DD\")\n",
    "    :param shuffle: bool, whether to shuffle the dataset (both training and testing), default is True\n",
    "    :param dropNaN: bool, whether to drop NaN values, default is True\n",
    "    :param split_by_ratio: bool, whether to split the data into training and testing by ratio of percent data, default is True\n",
    "    :param split_by_date: bool, whether to split the data into training and testing by date, default is False\n",
    "    :param split_date: str, the date to split the data into training and testing by date, default is None\n",
    "    :param test_size: ratio of test data to train data, default is 0.2 (80% for training and 20% for testing)\n",
    "    :param feature_columns: the list of features to feed into the model, default is everything grabbed from yahoo_fin\n",
    "    :param scale: whether to scale prices between 0 and 1, default is True\n",
    "    :return: \n",
    "    \"\"\"\n",
    "    \n",
    "    # ------------------------------------------------------------------------------------------------#\n",
    "    # Ticket to csv file, put it into folder dataset\n",
    "    ticker_data_filename = os.path.join(\"dataset\", f\"{ticker}_{TEST_START}_{TEST_END}.csv\") \n",
    "    ## a, see if ticker is already a loaded stock from yahoo finance\n",
    "    if os.path.exists(ticker_data_filename):\n",
    "        print(f'Loading data from {ticker_data_filename}')\n",
    "        # read csv file, take date column as index\n",
    "        df = pd.read_csv(ticker_data_filename, index_col=0)\n",
    "    else:\n",
    "        print(f'Downloading data for {ticker} from yahoo finance')\n",
    "        if not os.path.exists(\"dataset\"):\n",
    "            os.makedirs(\"dataset\")\n",
    "        # download data from yahoo finance before assign into dataframe\n",
    "        df = si.get_data(ticker, TEST_START, TEST_END)\n",
    "         ## d, Store the download data locally for future use\n",
    "        df.to_csv(ticker_data_filename)\n",
    "    # ------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "\n",
    "    # ------------------------------------------------------------------------------------------------#\n",
    "    ## b, Allow you to deal with the NaN issue in the data\n",
    "\n",
    "    # drop NaNs or fill nan with mean\n",
    "    if dropNaN:\n",
    "        df.dropna(inplace=True)\n",
    "    else:\n",
    "        df.fillna(df.mean())\n",
    "    # ------------------------------------------------------------------------------------------------#\n",
    "    \n",
    "    # this will contain all the elements we want to return from this function\n",
    "    result = {'df': df.copy()}\n",
    "    # we will also return the original dataframe itself\n",
    "\n",
    "    # ------------------------------------------------------------------------------------------------#\n",
    "    ## c, use different methods to split the data into train/test data; \n",
    "    # e.g. you can split it according to some specified ratio of train/test and you can specify to split it by date or randomly\n",
    "    if split_by_ratio:\n",
    "        # split the dataset into training & testing sets by ratio (not randomly splitting)\n",
    "        train_samples = int((1 - test_size) * len(df))\n",
    "        \n",
    "        print(f'Training samples: {train_samples}')\n",
    "        print(f'Test samples: {len(df)}')\n",
    "        \n",
    "        # :train_samples means from the beginning to train_samples, and train_samples: means from train_samples to the end\n",
    "        result['df_train'] = df[:train_samples]\n",
    "        result['df_test'] = df[train_samples:]\n",
    "        \n",
    "    elif split_by_date and split_date is not None:\n",
    "        # Convert split_date to a datetime object\n",
    "        split_date = pd.to_datetime(split_date)\n",
    "        \n",
    "        # Split by date on the index\n",
    "        result['df_train'] = df[df.index <= split_date]  # Take data from the start to split_date\n",
    "        result['df_test'] = df[df.index > split_date]  # Take data after split_date to the end\n",
    "\n",
    "    else:\n",
    "        # If neither split by ratio nor split by date, randomly split the dataset\n",
    "        result['df_train'], result['df_test'] = train_test_split(df, test_size=test_size, shuffle=shuffle)\n",
    "    # ------------------------------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "\n",
    "   \n",
    "    # ------------------------------------------------------------------------------------------------#\n",
    "    ## e, scale the feature columns and store the scalers in data structure \n",
    "    if scale:\n",
    "       result['column_scaler'] = df[feature_columns]\n",
    "       scale_min_max = MinMaxScaler(feature_range=(0, 1))\n",
    "       result['column_scaler'] = scale_min_max.fit_transform(result['column_scaler'])\n",
    "       result['column_scaler'] = pd.DataFrame(result['column_scaler'], columns = feature_columns)\n",
    "    # ------------------------------------------------------------------------------------------------#\n",
    "    \n",
    "    return result"
   ],
   "outputs": [],
   "execution_count": 70
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T04:35:08.150952Z",
     "start_time": "2024-09-30T04:35:08.144718Z"
    }
   },
   "source": [
    "# Amazon stock market\n",
    "TICKER = \"AMZN\"\n",
    "\n",
    "# Start and End date to read:\n",
    "TEST_START = '2020-01-01'\n",
    "TEST_END = '2023-01-01'\n",
    "\n",
    "# whether to scale feature columns & output price as well\n",
    "SCALE = True\n",
    "\n",
    "# whether to shuffle the dataset\n",
    "SHUFFLE = True\n",
    "\n",
    "# whether to split the training/testing set by date\n",
    "SPLIT_BY_DATE = False\n",
    "\n",
    "# test radio size, 0.2 is 20%\n",
    "TEST_SIZE = 0.2\n",
    "\n",
    "# features to use\n",
    "FEATURE_COLUMNS = [\"adjclose\", \"volume\", \"open\", \"high\", \"low\", \"close\"]"
   ],
   "outputs": [],
   "execution_count": 73
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T04:35:08.171605Z",
     "start_time": "2024-09-30T04:35:08.152647Z"
    }
   },
   "source": [
    "data = load_data(ticker=TICKER, TEST_START=TEST_START, TEST_END=TEST_END, scale=SCALE, dropNaN=True,\n",
    "          shuffle=SHUFFLE, split_by_date=SPLIT_BY_DATE, test_size=TEST_SIZE, feature_columns=FEATURE_COLUMNS)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from dataset/AMZN_2020-01-01_2023-01-01.csv\n",
      "Training samples: 604\n",
      "Test samples: 756\n"
     ]
    }
   ],
   "execution_count": 74
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T04:35:08.179333Z",
     "start_time": "2024-09-30T04:35:08.174045Z"
    }
   },
   "source": [
    "data[\"df\"].head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                 open       high        low      close   adjclose    volume  \\\n",
       "2020-01-02  93.750000  94.900497  93.207497  94.900497  94.900497  80580000   \n",
       "2020-01-03  93.224998  94.309998  93.224998  93.748497  93.748497  75288000   \n",
       "2020-01-06  93.000000  95.184502  93.000000  95.143997  95.143997  81236000   \n",
       "2020-01-07  95.224998  95.694504  94.601997  95.343002  95.343002  80898000   \n",
       "2020-01-08  94.902000  95.550003  94.321999  94.598503  94.598503  70160000   \n",
       "\n",
       "           ticker  \n",
       "2020-01-02   AMZN  \n",
       "2020-01-03   AMZN  \n",
       "2020-01-06   AMZN  \n",
       "2020-01-07   AMZN  \n",
       "2020-01-08   AMZN  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adjclose</th>\n",
       "      <th>volume</th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-02</th>\n",
       "      <td>93.750000</td>\n",
       "      <td>94.900497</td>\n",
       "      <td>93.207497</td>\n",
       "      <td>94.900497</td>\n",
       "      <td>94.900497</td>\n",
       "      <td>80580000</td>\n",
       "      <td>AMZN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-03</th>\n",
       "      <td>93.224998</td>\n",
       "      <td>94.309998</td>\n",
       "      <td>93.224998</td>\n",
       "      <td>93.748497</td>\n",
       "      <td>93.748497</td>\n",
       "      <td>75288000</td>\n",
       "      <td>AMZN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-06</th>\n",
       "      <td>93.000000</td>\n",
       "      <td>95.184502</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>95.143997</td>\n",
       "      <td>95.143997</td>\n",
       "      <td>81236000</td>\n",
       "      <td>AMZN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-07</th>\n",
       "      <td>95.224998</td>\n",
       "      <td>95.694504</td>\n",
       "      <td>94.601997</td>\n",
       "      <td>95.343002</td>\n",
       "      <td>95.343002</td>\n",
       "      <td>80898000</td>\n",
       "      <td>AMZN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-08</th>\n",
       "      <td>94.902000</td>\n",
       "      <td>95.550003</td>\n",
       "      <td>94.321999</td>\n",
       "      <td>94.598503</td>\n",
       "      <td>94.598503</td>\n",
       "      <td>70160000</td>\n",
       "      <td>AMZN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 75
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T04:35:08.185503Z",
     "start_time": "2024-09-30T04:35:08.180591Z"
    }
   },
   "cell_type": "code",
   "source": "data[\"column_scaler\"]",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     adjclose    volume      open      high       low     close\n",
       "0    0.124873  0.182574  0.111054  0.108587  0.114992  0.124873\n",
       "1    0.113875  0.163828  0.106060  0.102972  0.115161  0.113875\n",
       "2    0.127197  0.184897  0.103920  0.111287  0.112988  0.127197\n",
       "3    0.129097  0.183700  0.125085  0.116136  0.128460  0.129097\n",
       "4    0.121990  0.145664  0.122012  0.114762  0.125756  0.121990\n",
       "..        ...       ...       ...       ...       ...       ...\n",
       "751  0.032744  0.100584  0.011172  0.021868  0.015729  0.032744\n",
       "752  0.011647  0.100054  0.027534  0.017780  0.016405  0.011647\n",
       "753  0.000000  0.103400  0.006892  0.000000  0.003752  0.000000\n",
       "754  0.022530  0.091949  0.007558  0.010174  0.012058  0.022530\n",
       "755  0.020811  0.118180  0.009936  0.005420  0.011286  0.020811\n",
       "\n",
       "[756 rows x 6 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adjclose</th>\n",
       "      <th>volume</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.124873</td>\n",
       "      <td>0.182574</td>\n",
       "      <td>0.111054</td>\n",
       "      <td>0.108587</td>\n",
       "      <td>0.114992</td>\n",
       "      <td>0.124873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.113875</td>\n",
       "      <td>0.163828</td>\n",
       "      <td>0.106060</td>\n",
       "      <td>0.102972</td>\n",
       "      <td>0.115161</td>\n",
       "      <td>0.113875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.127197</td>\n",
       "      <td>0.184897</td>\n",
       "      <td>0.103920</td>\n",
       "      <td>0.111287</td>\n",
       "      <td>0.112988</td>\n",
       "      <td>0.127197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.129097</td>\n",
       "      <td>0.183700</td>\n",
       "      <td>0.125085</td>\n",
       "      <td>0.116136</td>\n",
       "      <td>0.128460</td>\n",
       "      <td>0.129097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.121990</td>\n",
       "      <td>0.145664</td>\n",
       "      <td>0.122012</td>\n",
       "      <td>0.114762</td>\n",
       "      <td>0.125756</td>\n",
       "      <td>0.121990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>0.032744</td>\n",
       "      <td>0.100584</td>\n",
       "      <td>0.011172</td>\n",
       "      <td>0.021868</td>\n",
       "      <td>0.015729</td>\n",
       "      <td>0.032744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>0.011647</td>\n",
       "      <td>0.100054</td>\n",
       "      <td>0.027534</td>\n",
       "      <td>0.017780</td>\n",
       "      <td>0.016405</td>\n",
       "      <td>0.011647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.103400</td>\n",
       "      <td>0.006892</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003752</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>0.022530</td>\n",
       "      <td>0.091949</td>\n",
       "      <td>0.007558</td>\n",
       "      <td>0.010174</td>\n",
       "      <td>0.012058</td>\n",
       "      <td>0.022530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>0.020811</td>\n",
       "      <td>0.118180</td>\n",
       "      <td>0.009936</td>\n",
       "      <td>0.005420</td>\n",
       "      <td>0.011286</td>\n",
       "      <td>0.020811</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>756 rows × 6 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 76
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T04:35:08.188005Z",
     "start_time": "2024-09-30T04:35:08.186331Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": 76
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
